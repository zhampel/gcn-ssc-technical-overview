{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.linalg import fractional_matrix_power as fracpow\n",
    "from numpy.linalg import matrix_power as matpow\n",
    "from numpy.linalg import eig as eigvv\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview of Semi-Supervised Classification <br> with GCNs by Kipf & Welling\n",
    "\n",
    "## Zigfried Hampel-Arias\n",
    "\n",
    "### ML6 -- Ghent, BE\n",
    "23 April, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Slides\n",
    "https://zhampel.github.io/gcn-ssc-technical-overview\n",
    "\n",
    "### Contact\n",
    "E-mail: [zhampel@wipac.wisc.edu](mailto:zhampel@wipac.wisc.edu)\n",
    "\n",
    "Find me on:\n",
    "\n",
    "<a href=\"https://zhampel.github.io/\">\n",
    "<img src=\"images/octocat.png\" alt=\"Go My GitHub\" width=\"60\" height=\"60\" border=\"0\"> </a>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/zhampel-arias/\">\n",
    "<img src=\"images/LinkedIn-InBug-2C.png\" alt=\"Go to my LinkedIn\" width=\"60\" height=\"60\" border=\"0\">\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "- Short Graph Terminology\n",
    "- Semi-Supervised Classification\n",
    "- Work by Kipf & Welling (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph Structured Data (GSD)\n",
    "\n",
    "Data sets in which data samples (nodes) demonstrate inter-connectivity or relationships (edges)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Describe with **graphs**.\n",
    "\n",
    "Graphs defined by\n",
    "\n",
    "- Set of $n$ nodes or vertices, $n = |\\mathcal{V}|$ \n",
    "- Set of $C$ features for each node, $C = |\\mathcal{C}|$\n",
    "- Set of $E$ edges, $E = |\\mathcal{E}|$\n",
    "- May include directionality and weights. Here just considering **simple** graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple Example\n",
    "\n",
    "A simple, undirected graph with $n=4$ vertices (nodes) each with $C = 1$ features connected by $E = 4$ edges.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "![simple_graph](images/simple_graph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical GSD Datasets\n",
    "\n",
    "- Social networks\n",
    "- Knowledge graphs\n",
    "- Citation databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Need a way to describe connectivity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Definitions\n",
    "\n",
    "Indices run over graph vertices: $i \\in [1,n]$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The **adjacency matrix** $A$ defines the connectivity of the graph:\n",
    "\n",
    "$$\n",
    "A_{ij} = \n",
    "\\begin{cases}\n",
    "%2 & \\text{ if loop at } i=j \\\\\n",
    "1 & \\text{ if edge from vertex i to j} \\\\\n",
    "0 & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The **degree matrix** $D$ is diagonal, giving the number of edges at each vertex:\n",
    "\n",
    "$$\n",
    "D_{ii} = \\sum_j A_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Adjacency matrix A for example\n",
    "A = np.zeros((4, 4))\n",
    "A[1,0] = 1\n",
    "A[2,1] = 1\n",
    "A[3,1] = 1\n",
    "A[3,2] = 1\n",
    "A += A.T\n",
    "# Degree matrix D for example\n",
    "D = np.zeros(A.shape)\n",
    "for i in range(0,A.shape[0]):\n",
    "    D[i,i] = A[:,i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple Example\n",
    "\n",
    "![simple_graph](images/simple_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A \t\t D\n",
      "[0. 1. 0. 0.]   [1. 0. 0. 0.]\n",
      "[1. 0. 1. 1.]   [0. 3. 0. 0.]\n",
      "[0. 1. 0. 1.]   [0. 0. 2. 0.]\n",
      "[0. 1. 1. 0.]   [0. 0. 0. 2.]\n",
      " Symmetric \t Diagonal\n"
     ]
    }
   ],
   "source": [
    "# Adjacency matrix A, Degree matrix D\n",
    "print(' A \\t\\t D')\n",
    "for j in range(0,A.shape[1]):\n",
    "    print('{}   {}'.format(A[:,j],D[:,j]))\n",
    "print(' Symmetric \\t Diagonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem:\n",
    "\n",
    "Can we build a predictive model on a GSD set that's not completely described?\n",
    "\n",
    "- Some but not all samples / nodes labelled: **Semi-Supervised Learning**\n",
    "- Can take advantage of node **connectivity** via $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How to include $A$ in algorithm?\n",
    "  - Preprocessing\n",
    "  - Model evaluation\n",
    "  - Training optimization (via loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semi-Supervised Learning\n",
    "\n",
    "One solution incorporates $A$ via **regularization** term in objective function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}\n",
    "&= \\underbrace{\\mathcal{L}_0}_{\\text{Supervised}} + \\underbrace{\\lambda \\, \\mathcal{L}_{\\text{reg}}}_{\\text{Unsupervised}} \\\\\n",
    "%&= L_0 + \\lambda \\, L_{\\text{reg}}(A) \\\\\n",
    "%\\\\\n",
    "%&= \\underbrace{L_0}_{\\text{Supervised}} + \\underbrace{\\lambda \\ \\ f(X)^{\\text{T}} \\ (D - A) \\, \\ f(X)}_{Unsupervised}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Supervised Component:\n",
    "\n",
    "- $\\mathcal{L}_0 \\sim$ categorical cross-entropy\n",
    "- Acts only on **labelled** subset of graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unsupervised Component:\n",
    "\n",
    "- $\\mathcal{L_{\\text{reg}}} = \\ \\sum_{i,j} A_{ij} \\ || \\ f(X_i) \\ - \\ f(X_j) \\ ||^2$\n",
    "  - Incorporates graph Laplacian $L = D \\ - \\ A$\n",
    "  - Describes smoothness\n",
    "- $f(X) \\sim$ neural network\n",
    "- $\\lambda$: regularization factor\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semi-Supervised Classification\n",
    "\n",
    "Incorporating $A$ via **regularization**:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}\n",
    "%&= \\underbrace{L_0}_{\\text{Supervised}} + \\underbrace{\\lambda \\, L_{\\text{reg}}}_{\\text{Unsupervised}} \\\\\n",
    "&= \\mathcal{L}_0 + \\lambda \\, \\mathcal{L}_{\\text{reg}} \\\\\n",
    "\\\\\n",
    "&= \\mathcal{L}_0 + \\lambda \\ \\sum_{i,j} A_{ij} \\ || \\ f(X_i) \\ - \\ f(X_j) \\ ||^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Connectivity encoded in regularization\n",
    "  - Assumption $\\rightarrow$ neighboring nodes share similar feature values\n",
    "  - Hyperparameter dependency $\\rightarrow$ tuning of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Not fully general model\n",
    "  - Connectivity $\\not \\to$ node similarity\n",
    "  - Problem dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Work by Kipf & Welling (2017)\n",
    "\n",
    "<br>\n",
    "Two main contributions:\n",
    "\n",
    "- Encode graph structure **within** model architecture\n",
    "- **Scalable** approach to semi-supervised learning via approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Incorporating Connectivity\n",
    "\n",
    "Embed $A$ **inside** neural network structure:\n",
    "\n",
    "$$\n",
    "f(X) \\rightarrow f(X,A)\n",
    "$$\n",
    "\n",
    "- Encode in activation value\n",
    "- Training of model weights explicitly includes node connectivity\n",
    "- Only need supervised component of objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolution on Graph\n",
    "\n",
    "Consider convolution parametrized by characteristic spectrum of graph structure:\n",
    "<!-- Consider convolving input with graph connectivity:  -->\n",
    "\n",
    "$$\n",
    "\\text{Conv} \\left( X \\right)= U \\ g_{\\theta} (\\Lambda) \\ U^{T} X\n",
    "$$\n",
    "\n",
    "- $U$ eigenvectors of $L_{\\text{norm}} = U \\ \\Lambda \\ U^{T} = I - D^{-1/2} \\ A \\ D^{-1/2}$\n",
    "- $\\Lambda$ eigenvalues of $L_{\\text{norm}}$\n",
    "- $g_{\\theta}(\\Lambda)$ spectral convolution parametrized by $\\theta \\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Potential issues:\n",
    "- Eigendecomposition $(U)$ may be prohibitively expensive!\n",
    "- Calculation $\\sim \\mathcal{O}(n^2)$ also expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Approximation via Expansion\n",
    "\n",
    "Approximate $g_{\\theta'}\\approx g_{\\theta}$\n",
    "- Truncated Chebyshev polynomial expansion:\n",
    "\n",
    "$$\n",
    "\\text{Conv} \\left( X \\right) \\approx U \\ \\left( \\theta'_0 + \\theta'_1 \\ \\Lambda \\ + ... + \\ \\theta'_k \\ \\Lambda^k \\right) \\ U^{T} \\ X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Furthermore, absorbing $U, \\ U^{T}$ into expansion:\n",
    "\n",
    "$$\n",
    "g_{\\theta'}(\\Lambda) \\rightarrow g_{\\theta'}(L_{\\text{norm}})\n",
    "= \\theta'_0 + \\theta'_1 \\ L_{\\text{norm}} \\ + ... + \\ \\theta'_k \\ L_{\\text{norm}}^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Filter now explicitly encodes graph connectivity $L_{\\text{norm}} = L_{\\text{norm}}(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Filter now explicitly encodes graph connectivity $L_{\\text{norm}} = L_{\\text{norm}}(A)$\n",
    "- $k^{\\text{th}}$ order term probes neighbors $\\sim k$ vertices away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Complexity in evaluating $g_{\\theta'}$ **scales linearly** with number of edges $\\mathcal{O}(k \\ E) < \\mathcal{O}(n^2)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Linear Model\n",
    "\n",
    "Let's limit to $k=1$\n",
    "\n",
    "$$\n",
    "\\text{Conv} \\left( X \\right) \\approx w \\ \\left( \\ I + D^{-1/2} \\ A \\ D^{-1/2} \\ \\right) \\ X\n",
    "$$\n",
    "\n",
    "  - Filter is **linear** in $A$\n",
    "  - Also limited to single filter parameter, $\\theta \\rightarrow w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Renormalization $\\tilde{A} = A+I$ to avoid numerical instabilities for repeated convolution gives:\n",
    "\n",
    "$$\n",
    "Z = \\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2} \\ X \\ W\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Full propagation rule at layer $l$, with activation function $\\sigma(\\cdot)$:\n",
    "\n",
    "$$\n",
    "H^{(l+1)} = \\sigma \\left( \\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2} \\ H^{(l)} \\ W^{(l)} \\right)\n",
    "$$\n",
    "\n",
    "- **Linear** in $A$ &rarr; **stack** $k$ convolutions to probe neighborhood $k$ nodes away\n",
    "- Complexity is $\\mathcal{O}( \\, E \\ C \\ k \\, )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To avoid numerical instabilities upon repeated action of convolution, renormalization $\\tilde{A} = A+I \\ , \\ \\tilde{D}$ gives final general filter operation:\n",
    "\n",
    "$$\n",
    "Z = \\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2} \\ X \\ \\Theta\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- Each vertex has $C$ features: $ X \\in \\mathbb{R}^{N \\times C} $\n",
    "- Parameters to convolve features: $ \\Theta \\in \\mathbb{R}^{C \\times F} $\n",
    "- Convolved signal: $Z \\in \\mathbb{R}^{N \\times F} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## A Linear Model\n",
    "\n",
    "Full propagation rule at layer $l$, $\\Theta^{(l)} \\rightarrow W^{(l)}$, with activation function $\\sigma(\\cdot)$:\n",
    "\n",
    "$$\n",
    "H^{(l+1)} = \\sigma \\left( \\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2} \\ H^{(l)} \\ W^{(l)} \\right)\n",
    "$$\n",
    "\n",
    "- **Linear** in $A$ &rarr; **stack** $k$ convolutions to probe neighborhood $k$ nodes away\n",
    "- Complexity is $\\mathcal{O}( \\, E \\ C \\ k \\, )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary of Propagation Rule\n",
    "\n",
    "\n",
    "![prop_rule](images/gcn_eqn.png)\n",
    "\n",
    "<p style=\"font-size:14px\">\n",
    "Image source: <a href=\"https://www.experoinc.com/post/node-classification-by-graph-convolutional-network\">Node Classification by Graph Convolutional Network</a> by Graham Ganssle\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Summary of Model\n",
    "\n",
    "Now have a convolution that \n",
    "\n",
    "- encodes graph structure **explicitly** with A\n",
    "  - Embeds $A$ directly in filter: $f(X) \\rightarrow f(X,A)$\n",
    "  - Makes no assumptions on nature of connectivity\n",
    "  - Strength of weights are learned including connectivity\n",
    "  \n",
    "- **linearly** scales with edges\n",
    "  - Can stack $k$ filter layers to probe $k^{\\text{th}}$-scale neighborhood\n",
    "  - Computationally accessible, $\\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2}$ preprocessing\n",
    "  \n",
    "\n",
    "Semi-Supervised Training &rarr; **learn** *weights* to predict node classification via **labelled** component of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demonstration\n",
    "\n",
    "Semi-supervised classification on karate club network\n",
    "\n",
    "- 34 nodes (featureless)\n",
    "- 154 edges (unweighted, undirected)\n",
    "- Four classes (clustering found by Brandes et al, 2008)\n",
    "- For demo, only **one** instance of each class is labelled!\n",
    "\n",
    "Model:\n",
    "\n",
    "- Three-layer GCN model\n",
    "- 300 training iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demonstration: Karate Club Graph\n",
    "\n",
    "![karate_club](images/karate_club.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"http://tkipf.github.io/graph-convolutional-networks/images/video.mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# MP4\n",
    "# Code found here: https://gist.github.com/christopherlovell/e3e70880c0b0ad666e7b5fe311320a62\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"http://tkipf.github.io/graph-convolutional-networks/images/video.mp4\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demonstration\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"http://tkipf.github.io/graph-convolutional-networks/images/video.mp4\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "\n",
    "<p style=\"font-size:14px\">\n",
    "Video source: <a href=\"http://tkipf.github.io/graph-convolutional-networks/\">Graph Convolutional Networks</a> by Thomas Kipf\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Performance\n",
    "\n",
    "Authors tested on GSD sets with different\n",
    "- Numbers of vertices, edges, features, & classes\n",
    "- Labelled fraction used for supervised training\n",
    "- Variants of layer-wise propagation rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Performance: Method Comparison on Datasets\n",
    "\n",
    "![baseline_perf](images/gcn_baseline_perf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Performance: Propagation Rule\n",
    "\n",
    "<br>\n",
    "\n",
    "![prop_rule_perf](images/gcn_prop_rule_perf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Performance: CPU/GPU\n",
    "\n",
    "Mean training time over 100 epochs. Factor $\\sim 2$ performance gain.\n",
    "\n",
    "![cpu_gpu_compare](images/gcn_cpu_gpu_timing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "Authors developed a model that\n",
    "\n",
    "- encodes graph structure **explicitly**\n",
    "  - Embeds $A$ directly: $f(X) \\rightarrow f(X,A)$\n",
    "  - **Learns** weights to predict node classification via **labelled** component of dataset\n",
    "- **linearly scales** with edges\n",
    "  - Can stack $k$ layers to probe $k^{\\text{th}}$-scale neighborhood\n",
    "  - Computationally accessible, $\\tilde{D}^{-1/2} \\ \\tilde{A} \\ \\tilde{D}^{-1/2}$ preprocessing\n",
    "  \n",
    "- outperforms other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you for your attention!\n",
    "\n",
    "<br>\n",
    "\n",
    "![final](images/sunset-gsl.jpg)\n",
    "\n",
    "## Any Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance: Number of Layers\n",
    "\n",
    "Two - three layers sufficient\n",
    "\n",
    "![layer_perf](images/gcn_layer_perf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations of Method\n",
    "\n",
    "- Memory\n",
    "  - Full-batch training $\\rightarrow$ linear memory requirements\n",
    "  - Mini-batch must account for neighborhood depth, potentially more approximations\n",
    "  \n",
    "- Non-simple graphs\n",
    "  - Current architecture doesn't include directed, weighted edges\n",
    "  - Potential to represent directionality via representation as undirected with additional nodes\n",
    "  \n",
    "- Locality\n",
    "  - Equal weighting given to self-connections & edges to neighbors\n",
    "  - Potential to incorporate trade-off parameter that can be learned: $\\tilde{A} = A+\\lambda \\, I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mathematics of Spectral Graph Theory\n",
    "\n",
    "For simple graph, the Laplacian is given by $L = D - A$,\n",
    "\n",
    "$$\n",
    "L_{ij} =\n",
    "\\begin{cases}\n",
    " \\text{deg} \\,  v_i & \\text{ if } i=j \\\\\n",
    " -1 & \\text{ if } i \\neq j \\text{ and } v_i \\text{ adjacent to } v_j \\\\\n",
    " 0 & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The symmetric, normalized Laplacian $L_{\\text{norm}}$ is given by\n",
    "\n",
    "$$\n",
    "L_{\\text{norm}} = D^{-1/2} \\, L \\, D^{-1/2} = I - D^{-1/2} \\, A \\, D^{-1/2} \\, ,\n",
    "$$\n",
    "\n",
    "$$\n",
    "L^{\\text{norm}}_{ij} =\n",
    "\\begin{cases}\n",
    " 1  &\\text{ if } i=j  \\text{ and deg} \\, v_i \\neq 0 \\\\\n",
    " -\\left( \\text{deg } v_i \\, \\text{deg } v_j \\right)^{-1/2} & \\text{ if } i \\neq j \\text{ and } v_i \\text{ adjacent to } v_j \\\\\n",
    " 0 & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "The resulting spectrum of eigenvalues are all non-negative real values: $\\lambda^{\\text{norm}}_i \\in \\mathbb{R}_{\\geq 0} \\ \\ , \\ \\forall i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mathematics of Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relation to Weisfeiler-Lehman Algorithm\n",
    "\n",
    "- Boils down node connectivity information to minimal representation\n",
    "- Replace hash function with $\\sigma(\\cdot)$\n",
    "- Define $c_{ij} = \\sqrt{\\, d_i \\ d_j}$\n",
    "\n",
    "$$\n",
    "h_i^{(l+1)} = \\sigma \\left( \\sum_{j\\in\\mathcal{N}+i} \\ \\frac{1}{c_{ij}} \\ h_{j}^{(l)} \\ W^{(l)}\\right)\n",
    "$$\n",
    "\n",
    "Interpretation: propagation rule is a parametrized, differentiable generalization of 1D WL alg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
